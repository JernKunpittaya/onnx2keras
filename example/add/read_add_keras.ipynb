{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../layers/dimension_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np2tf(x):\n",
    "    if isinstance(x, np.ndarray):\n",
    "        x = tf.convert_to_tensor(x, dtype=tf.float32)\n",
    "        return x, False\n",
    "    return x, True\n",
    "\n",
    "\n",
    "def match_tensor(x1:tf.Tensor or np.ndarray, x2:tf.Tensor or np.ndarray):\n",
    "    \n",
    "    x1, f1 = np2tf(x1)\n",
    "    x2, f2 = np2tf(x2)\n",
    "\n",
    "    # no need to transpose if all var are tensor, we assume tensor are computed by gragh.\n",
    "    if f1 and f2:\n",
    "        return x1, x2\n",
    "    \n",
    "    # ensure tensor is set to x1, weights set to x2\n",
    "    if f2:\n",
    "        x1, x2 = x2, x1\n",
    "\n",
    "    if x1.shape.ndims != x2.shape.ndims:\n",
    "        while x2.shape.ndims < x1.shape.ndims:\n",
    "            x2 = tf.expand_dims(x2, axis=0)\n",
    "    \n",
    "    new_shape = shape_NCD_to_NDC_format([i for i in range(len(x2.shape))])\n",
    "    x2 = tf.transpose(x2, new_shape)\n",
    "    return (x2, x1) if f2 else (x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ tf_reduce_min (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TFReduceMin</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ tf_reduce_min (\u001b[38;5;33mTFReduceMin\u001b[0m)     │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class TFAdd(keras.layers.Layer):\n",
    "    def __init__(self,tensor_grap,  node_weights, node_inputs, node_attribute, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.tensor_grap = tensor_grap\n",
    "        self.node_weights = node_weights\n",
    "        self.node_inputs = node_inputs\n",
    "        self.node_attribute = node_attribute\n",
    "        self.first_operand = tensor_grap[node_inputs[0]] if node_inputs[0] in tensor_grap else node_weights[node_inputs[0]]\n",
    "        self.second_operand = tensor_grap[node_inputs[1]] if node_inputs[1] in tensor_grap else node_weights[node_inputs[1]]\n",
    "        self.first_operand, self.second_operand = match_tensor(self.first_operand, self.second_operand)\n",
    "\n",
    "\n",
    "    def call(self, *args, **kwargs):\n",
    "        return keras.ops.add(args[0], args[1])\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"tensor_grap\":self.tensor_grap,\n",
    "            'node_weights':self.node_weights,\n",
    "            'node_inputs':self.node_inputs,\n",
    "            \"first_operand\": self.first_operand,\n",
    "             \"second_operand\": self.second_operand,\n",
    "            'node_attribute':self.node_attribute\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "class TFSub(keras.layers.Layer):\n",
    "    def __init__(self,tensor_grap,  node_weights, node_inputs, node_attribute, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.tensor_grap = tensor_grap\n",
    "        self.node_weights = node_weights\n",
    "        self.node_inputs = node_inputs\n",
    "        self.node_attribute = node_attribute\n",
    "        self.first_operand = tensor_grap[node_inputs[0]] if node_inputs[0] in tensor_grap else node_weights[node_inputs[0]]\n",
    "        self.second_operand = tensor_grap[node_inputs[1]] if node_inputs[1] in tensor_grap else node_weights[node_inputs[1]]\n",
    "        self.first_operand, self.second_operand = match_tensor(self.first_operand, self.second_operand)\n",
    "\n",
    "\n",
    "    def call(self, *args, **kwargs):\n",
    "        return keras.ops.subtract(args[0], args[1])\n",
    "        return self.first_operand - self.second_operand\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"tensor_grap\":self.tensor_grap,\n",
    "            'node_weights':self.node_weights,\n",
    "            'node_inputs':self.node_inputs,\n",
    "            \"first_operand\": self.first_operand,\n",
    "             \"second_operand\": self.second_operand,\n",
    "            'node_attribute':self.node_attribute\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "class TFEqual(keras.layers.Layer):\n",
    "    def __init__(self,tensor_grap,  node_weights, node_inputs, node_attribute, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.tensor_grap = tensor_grap\n",
    "        self.node_weights = node_weights\n",
    "        self.node_inputs = node_inputs\n",
    "        self.node_attribute = node_attribute\n",
    "        self.first_operand = tensor_grap[node_inputs[0]] if node_inputs[0] in tensor_grap else node_weights[node_inputs[0]]\n",
    "        self.second_operand = tensor_grap[node_inputs[1]] if node_inputs[1] in tensor_grap else node_weights[node_inputs[1]]\n",
    "        self.first_operand, self.second_operand = match_tensor(self.first_operand, self.second_operand)\n",
    "\n",
    "\n",
    "    def call(self, *args, **kwargs):\n",
    "        return keras.ops.equal(args[0], args[1])\n",
    "        return self.first_operand * self.second_operand\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"tensor_grap\":self.tensor_grap,\n",
    "            'node_weights':self.node_weights,\n",
    "            'node_inputs':self.node_inputs,\n",
    "            \"first_operand\": self.first_operand,\n",
    "             \"second_operand\": self.second_operand,\n",
    "            'node_attribute':self.node_attribute\n",
    "        })\n",
    "        return config\n",
    "class TFLog(keras.layers.Layer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "    def call(self, inputs, *args, **kwargs):\n",
    "        return keras.ops.log(inputs)\n",
    "\n",
    "class TFGreater(keras.layers.Layer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "    def call(self, *args, **kwargs):\n",
    "        return keras.ops.greater(args[0], args[1])\n",
    "\n",
    "\n",
    "class TFWhere(keras.layers.Layer):\n",
    "    def __init__(self,tensor_grap,  node_weights, node_inputs, node_attribute, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.tensor_grap = tensor_grap\n",
    "        self.node_weights = node_weights\n",
    "        self.node_inputs = node_inputs\n",
    "        self.node_attribute = node_attribute\n",
    "        self.true_value = tensor_grap[node_inputs[1]] if node_inputs[1] in tensor_grap else node_weights[node_inputs[1]]\n",
    "        self.false_value = tensor_grap[node_inputs[2]] if node_inputs[2] in tensor_grap else node_weights[node_inputs[2]]\n",
    "        self.true_value, self.false_value = match_tensor(self.true_value, self.false_value)\n",
    "\n",
    "\n",
    "    def call(self, *args, **kwargs):\n",
    "        return keras.ops.where(args[0], args[1], args[2])\n",
    "        return self.first_operand * self.second_operand\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"tensor_grap\":self.tensor_grap,\n",
    "            'node_weights':self.node_weights,\n",
    "            'node_inputs':self.node_inputs,\n",
    "            \"true_value\": self.true_value,\n",
    "             \"false_value\": self.false_value,\n",
    "            'node_attribute':self.node_attribute\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "class TFReduceMin(keras.layers.Layer):\n",
    "    def __init__(self, tensor_grap, node_weights, node_inputs, node_attribute, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.tensor_grap = tensor_grap\n",
    "        self.node_weights = node_weights\n",
    "        self.node_inputs = node_inputs\n",
    "        self.node_attribute = node_attribute\n",
    "\n",
    "\n",
    "        self.keep_dims = node_attribute.get(\"keepdims\", 1) == 1\n",
    "        # change, no shape for dict\n",
    "        input_shape_len = len(tensor_grap[node_inputs[0]]['config']['shape'])\n",
    "        self.axes = [channel_to_last_dimension(i) if i >=0 else channel_to_last_dimension(input_shape_len + i) for i in node_attribute.get(\"axes\", [-1])]\n",
    "\n",
    "    def call(self, inputs, *args, **kwargs):\n",
    "        return keras.ops.min(inputs, axis=self.axes, keepdims=self.keep_dims)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"tensor_grap\":self.tensor_grap,\n",
    "            'node_weights':self.node_weights,\n",
    "            'node_inputs':self.node_inputs,\n",
    "            'node_attribute':self.node_attribute\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    \n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "keras.saving.get_custom_objects().clear()\n",
    "custom_objects = {\"TFAdd\": TFAdd, \"TFLog\":TFLog, \"TFGreater\": TFGreater, \"TFWhere\":TFWhere, \"TFSub\":TFSub, \"TFEqual\":TFEqual, \"TFReduceMin\": TFReduceMin}\n",
    "with keras.saving.custom_object_scope(custom_objects):\n",
    "    model = load_model(\"add.keras\")\n",
    "    model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10.]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "input1 = torch.tensor([10, 40, 50], dtype = torch.float32).reshape(1,-1,1)\n",
    "input2 = torch.tensor([13, 4, 7], dtype = torch.float32).reshape(1,-1,1)\n",
    "# input3 = torch.tensor([3, 14, 7], dtype = torch.float32).reshape(1,-1,1)\n",
    "model.predict((input1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
